{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Danh sách thành viên\n",
    "##### 1. Trần Văn Phát - 5210091?\n",
    "##### 2. Bùi Văn Thống - 52100???\n",
    "##### 3. Nguyễn Minh Phú - 52100920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plotter\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12:15:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12:30:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12:45:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>10:45:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>11:00:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>11:15:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>11:30:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>11:45:00 PM</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time  Date Day of the week  CarCount  BikeCount  BusCount  \\\n",
       "0     12:00:00 AM    10         Tuesday        13          2         2   \n",
       "1     12:15:00 AM    10         Tuesday        14          1         1   \n",
       "2     12:30:00 AM    10         Tuesday        10          2         2   \n",
       "3     12:45:00 AM    10         Tuesday        10          2         2   \n",
       "4      1:00:00 AM    10         Tuesday        11          2         1   \n",
       "...           ...   ...             ...       ...        ...       ...   \n",
       "5947  10:45:00 PM     9        Thursday        16          3         1   \n",
       "5948  11:00:00 PM     9        Thursday        11          0         1   \n",
       "5949  11:15:00 PM     9        Thursday        15          4         1   \n",
       "5950  11:30:00 PM     9        Thursday        16          5         0   \n",
       "5951  11:45:00 PM     9        Thursday        14          3         1   \n",
       "\n",
       "      TruckCount  Total Traffic Situation  \n",
       "0             24     41            normal  \n",
       "1             36     52            normal  \n",
       "2             32     46            normal  \n",
       "3             36     50            normal  \n",
       "4             34     48            normal  \n",
       "...          ...    ...               ...  \n",
       "5947          36     56            normal  \n",
       "5948          30     42            normal  \n",
       "5949          25     45            normal  \n",
       "5950          27     48            normal  \n",
       "5951          15     33               low  \n",
       "\n",
       "[5952 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target của dataset này là \"Traffic Situation\" trong đó có 4 lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heavy', 'high', 'low', 'normal'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['Traffic Situation'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách thành tập train và test, để dành cho việc tách tập train thành 1 tập validation sau này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = train_test_split(df, test_size=0.25,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train:  (4464, 9)\n",
      "Shape of test (1488, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train: \", Train.shape)\n",
    "print(\"Shape of test\", Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biểu đồ dưới đây nhằm mục đích đánh số cho các feature và target thuộc categorical là \"Day of the week\" và \"Traffic Situation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "sns.countplot(x = Train[\"Day of the week\"])\n",
    "plotter.xticks(rotation = 90)\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x = Train[\"Traffic Situation\"])\n",
    "plotter.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong dataset này 2 categorial features là \"Time\" và \"Day of the week\" và một target cũng có categorical.\\\n",
    "Thông thường với các categorical features dạng thứ thứ bậc ta có thể dùng OrdinalEncoder trong sklearn để thực hiện việc encode. \\\n",
    "OrdinalEncoder giúp ta có thể encode n categories trong 1 categorical feature thành các số nguyên từ 0 đến n - 1. \\\n",
    "Tuy nhiên, OrdinalEncoder encode các categories một cách ngẫu nhiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Monday -> Encode [[1.]]\n",
      "Category: Tuesday -> Encode [[5.]]\n",
      "Category: Wednesday -> Encode [[6.]]\n",
      "Category: Thursday -> Encode [[4.]]\n",
      "Category: Friday -> Encode [[0.]]\n",
      "Category: Saturday -> Encode [[2.]]\n",
      "Category: Sunday -> Encode [[3.]]\n"
     ]
    }
   ],
   "source": [
    "tmpTrain = Train\n",
    "\n",
    "enc  = OrdinalEncoder()\n",
    "enc.fit_transform(np.array([tmpTrain['Day of the week']]).reshape(-1, 1))\n",
    "day_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "for day in day_of_week :\n",
    "    print(f'Category: {day} -> Encode {enc.transform(np.array([[day]]).reshape(-1, 1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì mục tiêu là dự đoán chính xác, chúng tôi cài đặt thủ công về việc encode \"Day of the week\" thủ công. \\\n",
    "Tương tự đối với target \"Traffic Situation\", ta cũng có thể encode bằng LabelEncoder trong sklearn, tuy nhiên vẫn phải encode thủ công.\\\n",
    "Còn với feature \"Time\" ta có thể dùng OrdinalEncoder (hoặc LabelEncoder) để thực hiện encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week_enc = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "traffic_sistuation = {\n",
    "    'low': 0,\n",
    "    'normal': 1,\n",
    "    'high': 2, \n",
    "    'heavy':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "\n",
    "df_temp_Train = Train\n",
    "df_temp_Test = Test\n",
    "\n",
    "df_temp_Train['Day of the week'] = df_temp_Train['Day of the week'].replace(day_of_week_enc)\n",
    "df_temp_Train['Time'] =  enc.fit_transform(np.array([df_temp_Train['Time']]).reshape(-1, 1)).reshape(-1)\n",
    "df_temp_Train['Traffic Situation'] = df_temp_Train['Traffic Situation'].replace(traffic_sistuation)\n",
    "\n",
    "df_temp_Test['Day of the week'] = df_temp_Test['Day of the week'].replace(day_of_week_enc)\n",
    "df_temp_Test['Time'] =  enc.transform(np.array([df_temp_Test['Time']]).reshape(-1, 1)).reshape(-1)\n",
    "df_temp_Test['Traffic Situation'] = df_temp_Test['Traffic Situation'].replace(traffic_sistuation)\n",
    "\n",
    "Train = df_temp_Train\n",
    "Test = df_temp_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>94.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>11.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>32.0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>59.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>19.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>48.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>75.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>11.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  Date  Day of the week  CarCount  BikeCount  BusCount  TruckCount  \\\n",
       "5703  94.0     7                2        31         10        40           9   \n",
       "521    2.0    15                7        46          5        11          13   \n",
       "2013  11.0    30                1         9          1         0          31   \n",
       "4808  32.0    29                7        18          4         1          31   \n",
       "5637  59.0     6                1       119         28        46           9   \n",
       "...    ...   ...              ...       ...        ...       ...         ...   \n",
       "5809  19.0     8                3        69         10         4          24   \n",
       "4720  48.0    28                6        18          3         0          17   \n",
       "173   75.0    11                3        72          1         9          32   \n",
       "1244   9.0    22                7         8          1         1          22   \n",
       "4989  11.0    30                1        14          1         0          27   \n",
       "\n",
       "      Total  Traffic Situation  \n",
       "5703     90                  1  \n",
       "521      75                  0  \n",
       "2013     41                  1  \n",
       "4808     54                  1  \n",
       "5637    202                  3  \n",
       "...     ...                ...  \n",
       "5809    107                  1  \n",
       "4720     38                  0  \n",
       "173     114                  2  \n",
       "1244     32                  1  \n",
       "4989     42                  1  \n",
       "\n",
       "[4464 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi đã thực hiện việc encode các categorical features. Bước tiếp theo là scale data về một khoảng nào đó để dễ tính toán.\\\n",
    "Chúng tôi, xin sử dụng StandardScaler trong sklearn đễ thực hiện.\\\n",
    "Đầu tiên cần tách thêm một lần nữa 2 tập Train, Test thành X_Train, y_train, X_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.drop(['Traffic Situation'], axis=1).values\n",
    "y_train = Train['Traffic Situation'].values\n",
    "\n",
    "X_test = Test.drop(['Traffic Situation'], axis=1).values\n",
    "y_test = Test['Traffic Situation'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 94.   7.   2. ...  40.   9.  90.]\n",
      " [  2.  15.   7. ...  11.  13.  75.]\n",
      " [ 11.  30.   1. ...   0.  31.  41.]\n",
      " ...\n",
      " [ 75.  11.   3. ...   9.  32. 114.]\n",
      " [  9.  22.   7. ...   1.  22.  32.]\n",
      " [ 11.  30.   1. ...   0.  27.  42.]]\n",
      "================================================================\n",
      "y_train:\n",
      "[1 0 1 ... 2 1 1]\n",
      "================================================================\n",
      "X_test:\n",
      "[[ 85.  28.   6. ...  15.  32. 129.]\n",
      " [ 17.  22.   7. ...   1.  26.  91.]\n",
      " [ 69.   7.   2. ...  11.  32. 108.]\n",
      " ...\n",
      " [ 95.  29.   7. ...   2.  29.  38.]\n",
      " [ 57.  16.   1. ...  33.  13. 184.]\n",
      " [  2.  20.   5. ...  16.  10. 153.]]\n",
      "================================================================\n",
      "y_test:\n",
      "[2 1 1 ... 1 3 1]\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "print('X_train:')\n",
    "print(X_train)\n",
    "print('='*64)\n",
    "\n",
    "print('y_train:')\n",
    "print(y_train)\n",
    "print('='*64)\n",
    "\n",
    "print('X_test:')\n",
    "print(X_test)\n",
    "print('='*64)\n",
    "\n",
    "print('y_test:')\n",
    "print(y_test)\n",
    "print('='*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo đây sẽ scale các tập X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.690340</td>\n",
       "      <td>-1.001728</td>\n",
       "      <td>-0.981514</td>\n",
       "      <td>-0.775747</td>\n",
       "      <td>-0.191491</td>\n",
       "      <td>2.178304</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>-0.347881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.647204</td>\n",
       "      <td>-0.106490</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-0.440935</td>\n",
       "      <td>-0.628289</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.514344</td>\n",
       "      <td>-0.616231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.320705</td>\n",
       "      <td>1.572081</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>-1.266804</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>1.137213</td>\n",
       "      <td>-1.224491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.558874</td>\n",
       "      <td>1.460176</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-1.065917</td>\n",
       "      <td>-0.715648</td>\n",
       "      <td>-0.955758</td>\n",
       "      <td>1.137213</td>\n",
       "      <td>-0.991921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420622</td>\n",
       "      <td>-1.113633</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>1.188481</td>\n",
       "      <td>1.380983</td>\n",
       "      <td>2.660467</td>\n",
       "      <td>-0.881356</td>\n",
       "      <td>1.655799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>-1.030484</td>\n",
       "      <td>-0.889823</td>\n",
       "      <td>-0.464464</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>-0.191491</td>\n",
       "      <td>-0.714676</td>\n",
       "      <td>0.494941</td>\n",
       "      <td>-0.043751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>0.021568</td>\n",
       "      <td>1.348271</td>\n",
       "      <td>1.086684</td>\n",
       "      <td>-1.065917</td>\n",
       "      <td>-0.803008</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>-0.147331</td>\n",
       "      <td>-1.278161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>1.001065</td>\n",
       "      <td>-0.554109</td>\n",
       "      <td>-0.464464</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-0.312873</td>\n",
       "      <td>1.228966</td>\n",
       "      <td>0.081479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>-1.393260</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>1.603734</td>\n",
       "      <td>-1.289125</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-0.955758</td>\n",
       "      <td>0.311434</td>\n",
       "      <td>-1.385501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>-1.320705</td>\n",
       "      <td>1.572081</td>\n",
       "      <td>-1.498563</td>\n",
       "      <td>-1.155200</td>\n",
       "      <td>-0.977727</td>\n",
       "      <td>-1.036118</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>-1.206601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4464 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     1.690340 -1.001728 -0.981514 -0.775747 -0.191491  2.178304 -0.881356   \n",
       "1    -1.647204 -0.106490  1.603734 -0.440935 -0.628289 -0.152152 -0.514344   \n",
       "2    -1.320705  1.572081 -1.498563 -1.266804 -0.977727 -1.036118  1.137213   \n",
       "3    -0.558874  1.460176  1.603734 -1.065917 -0.715648 -0.955758  1.137213   \n",
       "4     0.420622 -1.113633 -1.498563  1.188481  1.380983  2.660467 -0.881356   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4459 -1.030484 -0.889823 -0.464464  0.072443 -0.191491 -0.714676  0.494941   \n",
       "4460  0.021568  1.348271  1.086684 -1.065917 -0.803008 -1.036118 -0.147331   \n",
       "4461  1.001065 -0.554109 -0.464464  0.139405 -0.977727 -0.312873  1.228966   \n",
       "4462 -1.393260  0.676843  1.603734 -1.289125 -0.977727 -0.955758  0.311434   \n",
       "4463 -1.320705  1.572081 -1.498563 -1.155200 -0.977727 -1.036118  0.770200   \n",
       "\n",
       "             7  \n",
       "0    -0.347881  \n",
       "1    -0.616231  \n",
       "2    -1.224491  \n",
       "3    -0.991921  \n",
       "4     1.655799  \n",
       "...        ...  \n",
       "4459 -0.043751  \n",
       "4460 -1.278161  \n",
       "4461  0.081479  \n",
       "4462 -1.385501  \n",
       "4463 -1.206601  \n",
       "\n",
       "[4464 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng các models học máy cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì vấn đề trong bài toán này là Classification, nên chúng tôi sẽ sử dụng các mô hình học máy giải quyết về vấn đề classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng tôi cũng sử dụng classification_report để đáng giá các model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để đảm bảo tính công bằng các model sẽ không được cài đặt (configure) các tham số mà chỉ để các tham số ở mặc định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    KNeighborsClassifier(), \n",
    "    LogisticRegression(), \n",
    "    GaussianNB(), \n",
    "    RandomForestClassifier(), \n",
    "    AdaBoostClassifier(), \n",
    "    GradientBoostingClassifier(), \n",
    "    BaggingClassifier(), \n",
    "    SVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       219\n",
      "           1       0.90      0.96      0.93       874\n",
      "           2       0.76      0.49      0.60       110\n",
      "           3       0.93      0.93      0.93       285\n",
      "\n",
      "    accuracy                           0.90      1488\n",
      "   macro avg       0.88      0.81      0.84      1488\n",
      "weighted avg       0.90      0.90      0.90      1488\n",
      "\n",
      "================================================================\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.78       219\n",
      "           1       0.87      0.94      0.91       874\n",
      "           2       0.77      0.40      0.53       110\n",
      "           3       0.96      0.98      0.97       285\n",
      "\n",
      "    accuracy                           0.88      1488\n",
      "   macro avg       0.86      0.77      0.80      1488\n",
      "weighted avg       0.88      0.88      0.87      1488\n",
      "\n",
      "================================================================\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81       219\n",
      "           1       0.87      0.82      0.84       874\n",
      "           2       0.33      0.56      0.42       110\n",
      "           3       0.87      0.99      0.93       285\n",
      "\n",
      "    accuracy                           0.81      1488\n",
      "   macro avg       0.77      0.76      0.75      1488\n",
      "weighted avg       0.85      0.81      0.82      1488\n",
      "\n",
      "================================================================\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       0.99      0.98      0.99       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      0.99      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n",
      "AdaBoostClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       219\n",
      "           1       0.76      1.00      0.87       874\n",
      "           2       1.00      0.53      0.69       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           0.82      1488\n",
      "   macro avg       0.69      0.63      0.64      1488\n",
      "weighted avg       0.71      0.82      0.75      1488\n",
      "\n",
      "================================================================\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       1.00      1.00      1.00       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      1.00      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n",
      "BaggingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       219\n",
      "           1       1.00      1.00      1.00       874\n",
      "           2       1.00      0.99      1.00       110\n",
      "           3       1.00      1.00      1.00       285\n",
      "\n",
      "    accuracy                           1.00      1488\n",
      "   macro avg       1.00      1.00      1.00      1488\n",
      "weighted avg       1.00      1.00      1.00      1488\n",
      "\n",
      "================================================================\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       219\n",
      "           1       0.94      0.97      0.95       874\n",
      "           2       0.90      0.65      0.76       110\n",
      "           3       0.95      0.99      0.97       285\n",
      "\n",
      "    accuracy                           0.94      1488\n",
      "   macro avg       0.94      0.88      0.90      1488\n",
      "weighted avg       0.94      0.94      0.94      1488\n",
      "\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('='*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các mô hình Học Máy cơ bản có tỉ lệ dự đoán đúng cao, ví dụ như ở chỉ số accurancy của các mô hình luôn nằm trong khoảng từ 0.8 đến 1.0.\\\n",
    "Trong đó các mô hình dự đoán cao nhất có accuracy là 1.0 là Random Forest Classifier, Gradient Boosting Classifier, Bagging Classifier.\\\n",
    "Tiếp theo hãy thực nghiệm dữ liệu với Feed Forward Neural Network và Recurrent Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng Feed Forward Neural Network và Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax') # target có 4 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì vấn đề là classification, và output layer có activation là softmax, nên target cần phải encode theo onehot (có thể dùng dummy, hoặc to_categorial của keras.utils).\\\n",
    "Ở đây chúng tôi xin sử dụng to_categorical trong keras.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from keras.utils import to_categorical\n",
    "y_train_tmp = copy.copy(y_train)\n",
    "y_train_tmp = to_categorical(y_train_tmp)\n",
    "y_train_onehot = y_train_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 - 1s - loss: 1.2180 - accuracy: 0.4745 - 750ms/epoch - 17ms/step\n",
      "Epoch 2/200\n",
      "45/45 - 0s - loss: 0.8371 - accuracy: 0.7222 - 59ms/epoch - 1ms/step\n",
      "Epoch 3/200\n",
      "45/45 - 0s - loss: 0.6985 - accuracy: 0.7386 - 58ms/epoch - 1ms/step\n",
      "Epoch 4/200\n",
      "45/45 - 0s - loss: 0.6101 - accuracy: 0.7601 - 57ms/epoch - 1ms/step\n",
      "Epoch 5/200\n",
      "45/45 - 0s - loss: 0.5309 - accuracy: 0.8017 - 60ms/epoch - 1ms/step\n",
      "Epoch 6/200\n",
      "45/45 - 0s - loss: 0.4597 - accuracy: 0.8495 - 57ms/epoch - 1ms/step\n",
      "Epoch 7/200\n",
      "45/45 - 0s - loss: 0.4010 - accuracy: 0.8658 - 62ms/epoch - 1ms/step\n",
      "Epoch 8/200\n",
      "45/45 - 0s - loss: 0.3538 - accuracy: 0.8757 - 57ms/epoch - 1ms/step\n",
      "Epoch 9/200\n",
      "45/45 - 0s - loss: 0.3193 - accuracy: 0.8864 - 57ms/epoch - 1ms/step\n",
      "Epoch 10/200\n",
      "45/45 - 0s - loss: 0.2945 - accuracy: 0.8905 - 54ms/epoch - 1ms/step\n",
      "Epoch 11/200\n",
      "45/45 - 0s - loss: 0.2738 - accuracy: 0.8967 - 61ms/epoch - 1ms/step\n",
      "Epoch 12/200\n",
      "45/45 - 0s - loss: 0.2588 - accuracy: 0.9021 - 67ms/epoch - 1ms/step\n",
      "Epoch 13/200\n",
      "45/45 - 0s - loss: 0.2462 - accuracy: 0.9070 - 75ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "45/45 - 0s - loss: 0.2353 - accuracy: 0.9144 - 75ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "45/45 - 0s - loss: 0.2267 - accuracy: 0.9160 - 77ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "45/45 - 0s - loss: 0.2186 - accuracy: 0.9180 - 75ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "45/45 - 0s - loss: 0.2121 - accuracy: 0.9198 - 61ms/epoch - 1ms/step\n",
      "Epoch 18/200\n",
      "45/45 - 0s - loss: 0.2062 - accuracy: 0.9241 - 59ms/epoch - 1ms/step\n",
      "Epoch 19/200\n",
      "45/45 - 0s - loss: 0.2009 - accuracy: 0.9265 - 63ms/epoch - 1ms/step\n",
      "Epoch 20/200\n",
      "45/45 - 0s - loss: 0.1945 - accuracy: 0.9306 - 61ms/epoch - 1ms/step\n",
      "Epoch 21/200\n",
      "45/45 - 0s - loss: 0.1905 - accuracy: 0.9306 - 59ms/epoch - 1ms/step\n",
      "Epoch 22/200\n",
      "45/45 - 0s - loss: 0.1849 - accuracy: 0.9339 - 61ms/epoch - 1ms/step\n",
      "Epoch 23/200\n",
      "45/45 - 0s - loss: 0.1802 - accuracy: 0.9384 - 65ms/epoch - 1ms/step\n",
      "Epoch 24/200\n",
      "45/45 - 0s - loss: 0.1773 - accuracy: 0.9411 - 68ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "45/45 - 0s - loss: 0.1732 - accuracy: 0.9386 - 57ms/epoch - 1ms/step\n",
      "Epoch 26/200\n",
      "45/45 - 0s - loss: 0.1706 - accuracy: 0.9386 - 61ms/epoch - 1ms/step\n",
      "Epoch 27/200\n",
      "45/45 - 0s - loss: 0.1662 - accuracy: 0.9431 - 61ms/epoch - 1ms/step\n",
      "Epoch 28/200\n",
      "45/45 - 0s - loss: 0.1631 - accuracy: 0.9431 - 62ms/epoch - 1ms/step\n",
      "Epoch 29/200\n",
      "45/45 - 0s - loss: 0.1601 - accuracy: 0.9458 - 58ms/epoch - 1ms/step\n",
      "Epoch 30/200\n",
      "45/45 - 0s - loss: 0.1568 - accuracy: 0.9483 - 71ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "45/45 - 0s - loss: 0.1542 - accuracy: 0.9498 - 66ms/epoch - 1ms/step\n",
      "Epoch 32/200\n",
      "45/45 - 0s - loss: 0.1510 - accuracy: 0.9498 - 65ms/epoch - 1ms/step\n",
      "Epoch 33/200\n",
      "45/45 - 0s - loss: 0.1482 - accuracy: 0.9521 - 66ms/epoch - 1ms/step\n",
      "Epoch 34/200\n",
      "45/45 - 0s - loss: 0.1453 - accuracy: 0.9539 - 66ms/epoch - 1ms/step\n",
      "Epoch 35/200\n",
      "45/45 - 0s - loss: 0.1429 - accuracy: 0.9547 - 67ms/epoch - 1ms/step\n",
      "Epoch 36/200\n",
      "45/45 - 0s - loss: 0.1413 - accuracy: 0.9565 - 66ms/epoch - 1ms/step\n",
      "Epoch 37/200\n",
      "45/45 - 0s - loss: 0.1390 - accuracy: 0.9565 - 71ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "45/45 - 0s - loss: 0.1354 - accuracy: 0.9601 - 67ms/epoch - 1ms/step\n",
      "Epoch 39/200\n",
      "45/45 - 0s - loss: 0.1328 - accuracy: 0.9603 - 65ms/epoch - 1ms/step\n",
      "Epoch 40/200\n",
      "45/45 - 0s - loss: 0.1310 - accuracy: 0.9597 - 73ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "45/45 - 0s - loss: 0.1292 - accuracy: 0.9599 - 67ms/epoch - 1ms/step\n",
      "Epoch 42/200\n",
      "45/45 - 0s - loss: 0.1271 - accuracy: 0.9628 - 63ms/epoch - 1ms/step\n",
      "Epoch 43/200\n",
      "45/45 - 0s - loss: 0.1249 - accuracy: 0.9630 - 65ms/epoch - 1ms/step\n",
      "Epoch 44/200\n",
      "45/45 - 0s - loss: 0.1236 - accuracy: 0.9633 - 67ms/epoch - 1ms/step\n",
      "Epoch 45/200\n",
      "45/45 - 0s - loss: 0.1215 - accuracy: 0.9644 - 64ms/epoch - 1ms/step\n",
      "Epoch 46/200\n",
      "45/45 - 0s - loss: 0.1213 - accuracy: 0.9633 - 65ms/epoch - 1ms/step\n",
      "Epoch 47/200\n",
      "45/45 - 0s - loss: 0.1183 - accuracy: 0.9662 - 68ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "45/45 - 0s - loss: 0.1173 - accuracy: 0.9664 - 67ms/epoch - 1ms/step\n",
      "Epoch 49/200\n",
      "45/45 - 0s - loss: 0.1177 - accuracy: 0.9659 - 67ms/epoch - 1ms/step\n",
      "Epoch 50/200\n",
      "45/45 - 0s - loss: 0.1136 - accuracy: 0.9682 - 69ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "45/45 - 0s - loss: 0.1117 - accuracy: 0.9689 - 66ms/epoch - 1ms/step\n",
      "Epoch 52/200\n",
      "45/45 - 0s - loss: 0.1107 - accuracy: 0.9702 - 81ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "45/45 - 0s - loss: 0.1093 - accuracy: 0.9698 - 66ms/epoch - 1ms/step\n",
      "Epoch 54/200\n",
      "45/45 - 0s - loss: 0.1077 - accuracy: 0.9702 - 80ms/epoch - 2ms/step\n",
      "Epoch 55/200\n",
      "45/45 - 0s - loss: 0.1063 - accuracy: 0.9711 - 70ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "45/45 - 0s - loss: 0.1046 - accuracy: 0.9738 - 71ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "45/45 - 0s - loss: 0.1038 - accuracy: 0.9729 - 66ms/epoch - 1ms/step\n",
      "Epoch 58/200\n",
      "45/45 - 0s - loss: 0.1022 - accuracy: 0.9722 - 71ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "45/45 - 0s - loss: 0.1020 - accuracy: 0.9747 - 56ms/epoch - 1ms/step\n",
      "Epoch 60/200\n",
      "45/45 - 0s - loss: 0.1006 - accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 61/200\n",
      "45/45 - 0s - loss: 0.1004 - accuracy: 0.9727 - 55ms/epoch - 1ms/step\n",
      "Epoch 62/200\n",
      "45/45 - 0s - loss: 0.0986 - accuracy: 0.9736 - 55ms/epoch - 1ms/step\n",
      "Epoch 63/200\n",
      "45/45 - 0s - loss: 0.0974 - accuracy: 0.9758 - 108ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "45/45 - 0s - loss: 0.0955 - accuracy: 0.9760 - 54ms/epoch - 1ms/step\n",
      "Epoch 65/200\n",
      "45/45 - 0s - loss: 0.0942 - accuracy: 0.9751 - 55ms/epoch - 1ms/step\n",
      "Epoch 66/200\n",
      "45/45 - 0s - loss: 0.0929 - accuracy: 0.9767 - 53ms/epoch - 1ms/step\n",
      "Epoch 67/200\n",
      "45/45 - 0s - loss: 0.0919 - accuracy: 0.9769 - 57ms/epoch - 1ms/step\n",
      "Epoch 68/200\n",
      "45/45 - 0s - loss: 0.0910 - accuracy: 0.9774 - 53ms/epoch - 1ms/step\n",
      "Epoch 69/200\n",
      "45/45 - 0s - loss: 0.0901 - accuracy: 0.9776 - 56ms/epoch - 1ms/step\n",
      "Epoch 70/200\n",
      "45/45 - 0s - loss: 0.0898 - accuracy: 0.9774 - 57ms/epoch - 1ms/step\n",
      "Epoch 71/200\n",
      "45/45 - 0s - loss: 0.0878 - accuracy: 0.9780 - 55ms/epoch - 1ms/step\n",
      "Epoch 72/200\n",
      "45/45 - 0s - loss: 0.0865 - accuracy: 0.9796 - 57ms/epoch - 1ms/step\n",
      "Epoch 73/200\n",
      "45/45 - 0s - loss: 0.0858 - accuracy: 0.9803 - 60ms/epoch - 1ms/step\n",
      "Epoch 74/200\n",
      "45/45 - 0s - loss: 0.0848 - accuracy: 0.9810 - 53ms/epoch - 1ms/step\n",
      "Epoch 75/200\n",
      "45/45 - 0s - loss: 0.0838 - accuracy: 0.9814 - 55ms/epoch - 1ms/step\n",
      "Epoch 76/200\n",
      "45/45 - 0s - loss: 0.0840 - accuracy: 0.9792 - 54ms/epoch - 1ms/step\n",
      "Epoch 77/200\n",
      "45/45 - 0s - loss: 0.0825 - accuracy: 0.9810 - 55ms/epoch - 1ms/step\n",
      "Epoch 78/200\n",
      "45/45 - 0s - loss: 0.0812 - accuracy: 0.9816 - 56ms/epoch - 1ms/step\n",
      "Epoch 79/200\n",
      "45/45 - 0s - loss: 0.0806 - accuracy: 0.9812 - 57ms/epoch - 1ms/step\n",
      "Epoch 80/200\n",
      "45/45 - 0s - loss: 0.0802 - accuracy: 0.9814 - 55ms/epoch - 1ms/step\n",
      "Epoch 81/200\n",
      "45/45 - 0s - loss: 0.0796 - accuracy: 0.9810 - 54ms/epoch - 1ms/step\n",
      "Epoch 82/200\n",
      "45/45 - 0s - loss: 0.0777 - accuracy: 0.9819 - 56ms/epoch - 1ms/step\n",
      "Epoch 83/200\n",
      "45/45 - 0s - loss: 0.0766 - accuracy: 0.9825 - 58ms/epoch - 1ms/step\n",
      "Epoch 84/200\n",
      "45/45 - 0s - loss: 0.0778 - accuracy: 0.9805 - 56ms/epoch - 1ms/step\n",
      "Epoch 85/200\n",
      "45/45 - 0s - loss: 0.0752 - accuracy: 0.9836 - 60ms/epoch - 1ms/step\n",
      "Epoch 86/200\n",
      "45/45 - 0s - loss: 0.0748 - accuracy: 0.9836 - 55ms/epoch - 1ms/step\n",
      "Epoch 87/200\n",
      "45/45 - 0s - loss: 0.0731 - accuracy: 0.9850 - 54ms/epoch - 1ms/step\n",
      "Epoch 88/200\n",
      "45/45 - 0s - loss: 0.0732 - accuracy: 0.9836 - 58ms/epoch - 1ms/step\n",
      "Epoch 89/200\n",
      "45/45 - 0s - loss: 0.0728 - accuracy: 0.9823 - 59ms/epoch - 1ms/step\n",
      "Epoch 90/200\n",
      "45/45 - 0s - loss: 0.0719 - accuracy: 0.9832 - 55ms/epoch - 1ms/step\n",
      "Epoch 91/200\n",
      "45/45 - 0s - loss: 0.0705 - accuracy: 0.9836 - 58ms/epoch - 1ms/step\n",
      "Epoch 92/200\n",
      "45/45 - 0s - loss: 0.0709 - accuracy: 0.9836 - 56ms/epoch - 1ms/step\n",
      "Epoch 93/200\n",
      "45/45 - 0s - loss: 0.0693 - accuracy: 0.9843 - 58ms/epoch - 1ms/step\n",
      "Epoch 94/200\n",
      "45/45 - 0s - loss: 0.0687 - accuracy: 0.9854 - 58ms/epoch - 1ms/step\n",
      "Epoch 95/200\n",
      "45/45 - 0s - loss: 0.0678 - accuracy: 0.9852 - 56ms/epoch - 1ms/step\n",
      "Epoch 96/200\n",
      "45/45 - 0s - loss: 0.0675 - accuracy: 0.9841 - 56ms/epoch - 1ms/step\n",
      "Epoch 97/200\n",
      "45/45 - 0s - loss: 0.0667 - accuracy: 0.9854 - 55ms/epoch - 1ms/step\n",
      "Epoch 98/200\n",
      "45/45 - 0s - loss: 0.0658 - accuracy: 0.9859 - 57ms/epoch - 1ms/step\n",
      "Epoch 99/200\n",
      "45/45 - 0s - loss: 0.0647 - accuracy: 0.9861 - 55ms/epoch - 1ms/step\n",
      "Epoch 100/200\n",
      "45/45 - 0s - loss: 0.0654 - accuracy: 0.9861 - 55ms/epoch - 1ms/step\n",
      "Epoch 101/200\n",
      "45/45 - 0s - loss: 0.0640 - accuracy: 0.9850 - 53ms/epoch - 1ms/step\n",
      "Epoch 102/200\n",
      "45/45 - 0s - loss: 0.0629 - accuracy: 0.9872 - 61ms/epoch - 1ms/step\n",
      "Epoch 103/200\n",
      "45/45 - 0s - loss: 0.0624 - accuracy: 0.9872 - 58ms/epoch - 1ms/step\n",
      "Epoch 104/200\n",
      "45/45 - 0s - loss: 0.0629 - accuracy: 0.9839 - 59ms/epoch - 1ms/step\n",
      "Epoch 105/200\n",
      "45/45 - 0s - loss: 0.0614 - accuracy: 0.9863 - 61ms/epoch - 1ms/step\n",
      "Epoch 106/200\n",
      "45/45 - 0s - loss: 0.0600 - accuracy: 0.9872 - 62ms/epoch - 1ms/step\n",
      "Epoch 107/200\n",
      "45/45 - 0s - loss: 0.0603 - accuracy: 0.9857 - 64ms/epoch - 1ms/step\n",
      "Epoch 108/200\n",
      "45/45 - 0s - loss: 0.0597 - accuracy: 0.9866 - 59ms/epoch - 1ms/step\n",
      "Epoch 109/200\n",
      "45/45 - 0s - loss: 0.0581 - accuracy: 0.9877 - 63ms/epoch - 1ms/step\n",
      "Epoch 110/200\n",
      "45/45 - 0s - loss: 0.0579 - accuracy: 0.9872 - 67ms/epoch - 1ms/step\n",
      "Epoch 111/200\n",
      "45/45 - 0s - loss: 0.0573 - accuracy: 0.9881 - 63ms/epoch - 1ms/step\n",
      "Epoch 112/200\n",
      "45/45 - 0s - loss: 0.0571 - accuracy: 0.9877 - 64ms/epoch - 1ms/step\n",
      "Epoch 113/200\n",
      "45/45 - 0s - loss: 0.0556 - accuracy: 0.9879 - 66ms/epoch - 1ms/step\n",
      "Epoch 114/200\n",
      "45/45 - 0s - loss: 0.0555 - accuracy: 0.9888 - 62ms/epoch - 1ms/step\n",
      "Epoch 115/200\n",
      "45/45 - 0s - loss: 0.0556 - accuracy: 0.9868 - 62ms/epoch - 1ms/step\n",
      "Epoch 116/200\n",
      "45/45 - 0s - loss: 0.0541 - accuracy: 0.9881 - 60ms/epoch - 1ms/step\n",
      "Epoch 117/200\n",
      "45/45 - 0s - loss: 0.0538 - accuracy: 0.9879 - 63ms/epoch - 1ms/step\n",
      "Epoch 118/200\n",
      "45/45 - 0s - loss: 0.0532 - accuracy: 0.9888 - 61ms/epoch - 1ms/step\n",
      "Epoch 119/200\n",
      "45/45 - 0s - loss: 0.0530 - accuracy: 0.9877 - 63ms/epoch - 1ms/step\n",
      "Epoch 120/200\n",
      "45/45 - 0s - loss: 0.0516 - accuracy: 0.9886 - 63ms/epoch - 1ms/step\n",
      "Epoch 121/200\n",
      "45/45 - 0s - loss: 0.0514 - accuracy: 0.9892 - 60ms/epoch - 1ms/step\n",
      "Epoch 122/200\n",
      "45/45 - 0s - loss: 0.0504 - accuracy: 0.9899 - 62ms/epoch - 1ms/step\n",
      "Epoch 123/200\n",
      "45/45 - 0s - loss: 0.0505 - accuracy: 0.9899 - 63ms/epoch - 1ms/step\n",
      "Epoch 124/200\n",
      "45/45 - 0s - loss: 0.0503 - accuracy: 0.9875 - 65ms/epoch - 1ms/step\n",
      "Epoch 125/200\n",
      "45/45 - 0s - loss: 0.0494 - accuracy: 0.9895 - 63ms/epoch - 1ms/step\n",
      "Epoch 126/200\n",
      "45/45 - 0s - loss: 0.0498 - accuracy: 0.9890 - 62ms/epoch - 1ms/step\n",
      "Epoch 127/200\n",
      "45/45 - 0s - loss: 0.0485 - accuracy: 0.9899 - 57ms/epoch - 1ms/step\n",
      "Epoch 128/200\n",
      "45/45 - 0s - loss: 0.0481 - accuracy: 0.9904 - 65ms/epoch - 1ms/step\n",
      "Epoch 129/200\n",
      "45/45 - 0s - loss: 0.0470 - accuracy: 0.9901 - 58ms/epoch - 1ms/step\n",
      "Epoch 130/200\n",
      "45/45 - 0s - loss: 0.0471 - accuracy: 0.9892 - 61ms/epoch - 1ms/step\n",
      "Epoch 131/200\n",
      "45/45 - 0s - loss: 0.0470 - accuracy: 0.9895 - 55ms/epoch - 1ms/step\n",
      "Epoch 132/200\n",
      "45/45 - 0s - loss: 0.0466 - accuracy: 0.9901 - 60ms/epoch - 1ms/step\n",
      "Epoch 133/200\n",
      "45/45 - 0s - loss: 0.0462 - accuracy: 0.9906 - 58ms/epoch - 1ms/step\n",
      "Epoch 134/200\n",
      "45/45 - 0s - loss: 0.0455 - accuracy: 0.9899 - 59ms/epoch - 1ms/step\n",
      "Epoch 135/200\n",
      "45/45 - 0s - loss: 0.0448 - accuracy: 0.9910 - 58ms/epoch - 1ms/step\n",
      "Epoch 136/200\n",
      "45/45 - 0s - loss: 0.0439 - accuracy: 0.9917 - 62ms/epoch - 1ms/step\n",
      "Epoch 137/200\n",
      "45/45 - 0s - loss: 0.0440 - accuracy: 0.9897 - 80ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "45/45 - 0s - loss: 0.0437 - accuracy: 0.9913 - 68ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "45/45 - 0s - loss: 0.0431 - accuracy: 0.9917 - 70ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "45/45 - 0s - loss: 0.0434 - accuracy: 0.9895 - 66ms/epoch - 1ms/step\n",
      "Epoch 141/200\n",
      "45/45 - 0s - loss: 0.0428 - accuracy: 0.9913 - 55ms/epoch - 1ms/step\n",
      "Epoch 142/200\n",
      "45/45 - 0s - loss: 0.0421 - accuracy: 0.9913 - 54ms/epoch - 1ms/step\n",
      "Epoch 143/200\n",
      "45/45 - 0s - loss: 0.0425 - accuracy: 0.9899 - 52ms/epoch - 1ms/step\n",
      "Epoch 144/200\n",
      "45/45 - 0s - loss: 0.0414 - accuracy: 0.9910 - 73ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "45/45 - 0s - loss: 0.0418 - accuracy: 0.9904 - 61ms/epoch - 1ms/step\n",
      "Epoch 146/200\n",
      "45/45 - 0s - loss: 0.0412 - accuracy: 0.9906 - 51ms/epoch - 1ms/step\n",
      "Epoch 147/200\n",
      "45/45 - 0s - loss: 0.0399 - accuracy: 0.9915 - 51ms/epoch - 1ms/step\n",
      "Epoch 148/200\n",
      "45/45 - 0s - loss: 0.0398 - accuracy: 0.9922 - 52ms/epoch - 1ms/step\n",
      "Epoch 149/200\n",
      "45/45 - 0s - loss: 0.0394 - accuracy: 0.9913 - 53ms/epoch - 1ms/step\n",
      "Epoch 150/200\n",
      "45/45 - 0s - loss: 0.0389 - accuracy: 0.9915 - 55ms/epoch - 1ms/step\n",
      "Epoch 151/200\n",
      "45/45 - 0s - loss: 0.0393 - accuracy: 0.9915 - 54ms/epoch - 1ms/step\n",
      "Epoch 152/200\n",
      "45/45 - 0s - loss: 0.0387 - accuracy: 0.9917 - 54ms/epoch - 1ms/step\n",
      "Epoch 153/200\n",
      "45/45 - 0s - loss: 0.0392 - accuracy: 0.9922 - 54ms/epoch - 1ms/step\n",
      "Epoch 154/200\n",
      "45/45 - 0s - loss: 0.0385 - accuracy: 0.9904 - 54ms/epoch - 1ms/step\n",
      "Epoch 155/200\n",
      "45/45 - 0s - loss: 0.0376 - accuracy: 0.9926 - 53ms/epoch - 1ms/step\n",
      "Epoch 156/200\n",
      "45/45 - 0s - loss: 0.0372 - accuracy: 0.9917 - 54ms/epoch - 1ms/step\n",
      "Epoch 157/200\n",
      "45/45 - 0s - loss: 0.0379 - accuracy: 0.9915 - 55ms/epoch - 1ms/step\n",
      "Epoch 158/200\n",
      "45/45 - 0s - loss: 0.0362 - accuracy: 0.9928 - 57ms/epoch - 1ms/step\n",
      "Epoch 159/200\n",
      "45/45 - 0s - loss: 0.0366 - accuracy: 0.9933 - 55ms/epoch - 1ms/step\n",
      "Epoch 160/200\n",
      "45/45 - 0s - loss: 0.0361 - accuracy: 0.9917 - 55ms/epoch - 1ms/step\n",
      "Epoch 161/200\n",
      "45/45 - 0s - loss: 0.0359 - accuracy: 0.9913 - 54ms/epoch - 1ms/step\n",
      "Epoch 162/200\n",
      "45/45 - 0s - loss: 0.0362 - accuracy: 0.9924 - 64ms/epoch - 1ms/step\n",
      "Epoch 163/200\n",
      "45/45 - 0s - loss: 0.0358 - accuracy: 0.9924 - 75ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "45/45 - 0s - loss: 0.0361 - accuracy: 0.9913 - 65ms/epoch - 1ms/step\n",
      "Epoch 165/200\n",
      "45/45 - 0s - loss: 0.0356 - accuracy: 0.9917 - 61ms/epoch - 1ms/step\n",
      "Epoch 166/200\n",
      "45/45 - 0s - loss: 0.0352 - accuracy: 0.9917 - 56ms/epoch - 1ms/step\n",
      "Epoch 167/200\n",
      "45/45 - 0s - loss: 0.0348 - accuracy: 0.9926 - 68ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "45/45 - 0s - loss: 0.0335 - accuracy: 0.9926 - 63ms/epoch - 1ms/step\n",
      "Epoch 169/200\n",
      "45/45 - 0s - loss: 0.0334 - accuracy: 0.9931 - 61ms/epoch - 1ms/step\n",
      "Epoch 170/200\n",
      "45/45 - 0s - loss: 0.0331 - accuracy: 0.9926 - 59ms/epoch - 1ms/step\n",
      "Epoch 171/200\n",
      "45/45 - 0s - loss: 0.0333 - accuracy: 0.9922 - 60ms/epoch - 1ms/step\n",
      "Epoch 172/200\n",
      "45/45 - 0s - loss: 0.0336 - accuracy: 0.9926 - 59ms/epoch - 1ms/step\n",
      "Epoch 173/200\n",
      "45/45 - 0s - loss: 0.0330 - accuracy: 0.9922 - 58ms/epoch - 1ms/step\n",
      "Epoch 174/200\n",
      "45/45 - 0s - loss: 0.0337 - accuracy: 0.9931 - 56ms/epoch - 1ms/step\n",
      "Epoch 175/200\n",
      "45/45 - 0s - loss: 0.0325 - accuracy: 0.9937 - 54ms/epoch - 1ms/step\n",
      "Epoch 176/200\n",
      "45/45 - 0s - loss: 0.0316 - accuracy: 0.9935 - 60ms/epoch - 1ms/step\n",
      "Epoch 177/200\n",
      "45/45 - 0s - loss: 0.0316 - accuracy: 0.9940 - 58ms/epoch - 1ms/step\n",
      "Epoch 178/200\n",
      "45/45 - 0s - loss: 0.0324 - accuracy: 0.9924 - 55ms/epoch - 1ms/step\n",
      "Epoch 179/200\n",
      "45/45 - 0s - loss: 0.0318 - accuracy: 0.9944 - 55ms/epoch - 1ms/step\n",
      "Epoch 180/200\n",
      "45/45 - 0s - loss: 0.0320 - accuracy: 0.9926 - 60ms/epoch - 1ms/step\n",
      "Epoch 181/200\n",
      "45/45 - 0s - loss: 0.0311 - accuracy: 0.9931 - 55ms/epoch - 1ms/step\n",
      "Epoch 182/200\n",
      "45/45 - 0s - loss: 0.0310 - accuracy: 0.9937 - 54ms/epoch - 1ms/step\n",
      "Epoch 183/200\n",
      "45/45 - 0s - loss: 0.0306 - accuracy: 0.9931 - 57ms/epoch - 1ms/step\n",
      "Epoch 184/200\n",
      "45/45 - 0s - loss: 0.0306 - accuracy: 0.9942 - 54ms/epoch - 1ms/step\n",
      "Epoch 185/200\n",
      "45/45 - 0s - loss: 0.0305 - accuracy: 0.9933 - 56ms/epoch - 1ms/step\n",
      "Epoch 186/200\n",
      "45/45 - 0s - loss: 0.0302 - accuracy: 0.9933 - 55ms/epoch - 1ms/step\n",
      "Epoch 187/200\n",
      "45/45 - 0s - loss: 0.0294 - accuracy: 0.9944 - 55ms/epoch - 1ms/step\n",
      "Epoch 188/200\n",
      "45/45 - 0s - loss: 0.0297 - accuracy: 0.9933 - 55ms/epoch - 1ms/step\n",
      "Epoch 189/200\n",
      "45/45 - 0s - loss: 0.0291 - accuracy: 0.9931 - 57ms/epoch - 1ms/step\n",
      "Epoch 190/200\n",
      "45/45 - 0s - loss: 0.0293 - accuracy: 0.9935 - 54ms/epoch - 1ms/step\n",
      "Epoch 191/200\n",
      "45/45 - 0s - loss: 0.0295 - accuracy: 0.9924 - 53ms/epoch - 1ms/step\n",
      "Epoch 192/200\n",
      "45/45 - 0s - loss: 0.0291 - accuracy: 0.9937 - 97ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "45/45 - 0s - loss: 0.0281 - accuracy: 0.9940 - 60ms/epoch - 1ms/step\n",
      "Epoch 194/200\n",
      "45/45 - 0s - loss: 0.0283 - accuracy: 0.9933 - 64ms/epoch - 1ms/step\n",
      "Epoch 195/200\n",
      "45/45 - 0s - loss: 0.0281 - accuracy: 0.9948 - 75ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "45/45 - 0s - loss: 0.0282 - accuracy: 0.9942 - 57ms/epoch - 1ms/step\n",
      "Epoch 197/200\n",
      "45/45 - 0s - loss: 0.0284 - accuracy: 0.9944 - 52ms/epoch - 1ms/step\n",
      "Epoch 198/200\n",
      "45/45 - 0s - loss: 0.0281 - accuracy: 0.9937 - 53ms/epoch - 1ms/step\n",
      "Epoch 199/200\n",
      "45/45 - 0s - loss: 0.0278 - accuracy: 0.9944 - 52ms/epoch - 1ms/step\n",
      "Epoch 200/200\n",
      "45/45 - 0s - loss: 0.0271 - accuracy: 0.9951 - 50ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29897756bd0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_onehot, epochs=200, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tóm tắt các thông tin sau khi train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 16)                144       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 820 (3.20 KB)\n",
      "Trainable params: 820 (3.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.79702461e-22, 6.17517158e-02, 9.38248336e-01, 7.79727550e-16],\n",
       "       [4.48850638e-19, 1.00000000e+00, 9.89710601e-18, 1.05858330e-28],\n",
       "       [4.82290286e-30, 9.85349655e-01, 1.46502936e-02, 1.22002545e-23],\n",
       "       ...,\n",
       "       [3.07369072e-30, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.63725099e-13, 6.22724835e-03, 5.37539541e-04, 9.93235171e-01],\n",
       "       [2.89651666e-07, 9.99999642e-01, 2.41934339e-09, 6.48902869e-08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với mỗi hàng trong ma trận trên chính là xác xuất của từng class khi model dự đoán 1 input.\\\n",
    "Với mỗi hàng ta sẽ lấy index của element có giá trị lớn nhất, index này cũng chính là class mà model dự đoán cho 1 input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy rằng model FFNN này có tỉ lệ dự đóan của model này ở mức cao lên đến <b>99%<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       219\n",
      "           1       0.98      0.99      0.99       874\n",
      "           2       0.95      0.95      0.95       110\n",
      "           3       0.99      0.99      0.99       285\n",
      "\n",
      "    accuracy                           0.99      1488\n",
      "   macro avg       0.98      0.98      0.98      1488\n",
      "weighted avg       0.99      0.99      0.99      1488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng early stopping để tránh overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chọn feature time làm dữ liệu, target vẫn là traffic situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df\n",
    "df_tmp['Time'] = pd.to_datetime(df_tmp['Time'])\n",
    "df_tmp['Time'] = df_tmp['Time'].apply(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tmp[['Time']]\n",
    "y = df_tmp['Traffic Situation'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo model RNN với Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.LSTM(128, activation='relu', input_shape=(X_train.shape[1], 1), kernel_regularizer=l2(0.01)),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "48/48 [==============================] - 3s 14ms/step - loss: 1.3421 - accuracy: 0.5812 - val_loss: 1.2674 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.2081 - accuracy: 0.6011 - val_loss: 1.1167 - val_accuracy: 0.6280\n",
      "Epoch 3/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.1023 - accuracy: 0.6011 - val_loss: 1.0475 - val_accuracy: 0.6280\n",
      "Epoch 4/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0721 - accuracy: 0.6011 - val_loss: 1.0344 - val_accuracy: 0.6280\n",
      "Epoch 5/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0625 - accuracy: 0.6011 - val_loss: 1.0300 - val_accuracy: 0.6280\n",
      "Epoch 6/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0571 - accuracy: 0.6011 - val_loss: 1.0268 - val_accuracy: 0.6280\n",
      "Epoch 7/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0535 - accuracy: 0.6011 - val_loss: 1.0246 - val_accuracy: 0.6280\n",
      "Epoch 8/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0500 - accuracy: 0.6011 - val_loss: 1.0220 - val_accuracy: 0.6280\n",
      "Epoch 9/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0467 - accuracy: 0.6011 - val_loss: 1.0188 - val_accuracy: 0.6280\n",
      "Epoch 10/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0433 - accuracy: 0.6011 - val_loss: 1.0159 - val_accuracy: 0.6280\n",
      "Epoch 11/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0393 - accuracy: 0.6011 - val_loss: 1.0118 - val_accuracy: 0.6280\n",
      "Epoch 12/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0355 - accuracy: 0.6011 - val_loss: 1.0080 - val_accuracy: 0.6280\n",
      "Epoch 13/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0314 - accuracy: 0.6011 - val_loss: 1.0047 - val_accuracy: 0.6280\n",
      "Epoch 14/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0268 - accuracy: 0.6011 - val_loss: 1.0005 - val_accuracy: 0.6280\n",
      "Epoch 15/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 1.0224 - accuracy: 0.6011 - val_loss: 0.9969 - val_accuracy: 0.6280\n",
      "Epoch 16/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 1.0181 - accuracy: 0.6011 - val_loss: 0.9924 - val_accuracy: 0.6280\n",
      "Epoch 17/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0141 - accuracy: 0.6011 - val_loss: 0.9891 - val_accuracy: 0.6280\n",
      "Epoch 18/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0096 - accuracy: 0.6011 - val_loss: 0.9851 - val_accuracy: 0.6280\n",
      "Epoch 19/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1.0058 - accuracy: 0.6011 - val_loss: 0.9828 - val_accuracy: 0.6280\n",
      "Epoch 20/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.0025 - accuracy: 0.6011 - val_loss: 0.9801 - val_accuracy: 0.6280\n",
      "Epoch 21/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9993 - accuracy: 0.6011 - val_loss: 0.9757 - val_accuracy: 0.6280\n",
      "Epoch 22/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9963 - accuracy: 0.6011 - val_loss: 0.9731 - val_accuracy: 0.6280\n",
      "Epoch 23/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9940 - accuracy: 0.6011 - val_loss: 0.9707 - val_accuracy: 0.6280\n",
      "Epoch 24/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9909 - accuracy: 0.6011 - val_loss: 0.9688 - val_accuracy: 0.6280\n",
      "Epoch 25/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9886 - accuracy: 0.6011 - val_loss: 0.9672 - val_accuracy: 0.6280\n",
      "Epoch 26/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9865 - accuracy: 0.6011 - val_loss: 0.9646 - val_accuracy: 0.6280\n",
      "Epoch 27/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9848 - accuracy: 0.6011 - val_loss: 0.9627 - val_accuracy: 0.6280\n",
      "Epoch 28/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9831 - accuracy: 0.6011 - val_loss: 0.9635 - val_accuracy: 0.6280\n",
      "Epoch 29/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.9812 - accuracy: 0.6011 - val_loss: 0.9604 - val_accuracy: 0.6280\n",
      "Epoch 30/200\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.9799 - accuracy: 0.6011 - val_loss: 0.9577 - val_accuracy: 0.6280\n",
      "Epoch 31/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9790 - accuracy: 0.6011 - val_loss: 0.9595 - val_accuracy: 0.6280\n",
      "Epoch 32/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9771 - accuracy: 0.6011 - val_loss: 0.9568 - val_accuracy: 0.6280\n",
      "Epoch 33/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9756 - accuracy: 0.6011 - val_loss: 0.9551 - val_accuracy: 0.6280\n",
      "Epoch 34/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9742 - accuracy: 0.6011 - val_loss: 0.9540 - val_accuracy: 0.6280\n",
      "Epoch 35/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9736 - accuracy: 0.6011 - val_loss: 0.9532 - val_accuracy: 0.6280\n",
      "Epoch 36/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9724 - accuracy: 0.6011 - val_loss: 0.9520 - val_accuracy: 0.6280\n",
      "Epoch 37/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9715 - accuracy: 0.6011 - val_loss: 0.9519 - val_accuracy: 0.6280\n",
      "Epoch 38/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9706 - accuracy: 0.6011 - val_loss: 0.9505 - val_accuracy: 0.6280\n",
      "Epoch 39/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9701 - accuracy: 0.6011 - val_loss: 0.9496 - val_accuracy: 0.6280\n",
      "Epoch 40/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9694 - accuracy: 0.6011 - val_loss: 0.9495 - val_accuracy: 0.6280\n",
      "Epoch 41/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9684 - accuracy: 0.6011 - val_loss: 0.9490 - val_accuracy: 0.6280\n",
      "Epoch 42/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9681 - accuracy: 0.6011 - val_loss: 0.9482 - val_accuracy: 0.6280\n",
      "Epoch 43/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9669 - accuracy: 0.6011 - val_loss: 0.9467 - val_accuracy: 0.6280\n",
      "Epoch 44/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9665 - accuracy: 0.6011 - val_loss: 0.9463 - val_accuracy: 0.6280\n",
      "Epoch 45/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9658 - accuracy: 0.6011 - val_loss: 0.9458 - val_accuracy: 0.6280\n",
      "Epoch 46/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9653 - accuracy: 0.6011 - val_loss: 0.9454 - val_accuracy: 0.6280\n",
      "Epoch 47/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9651 - accuracy: 0.6011 - val_loss: 0.9444 - val_accuracy: 0.6280\n",
      "Epoch 48/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9641 - accuracy: 0.6011 - val_loss: 0.9450 - val_accuracy: 0.6280\n",
      "Epoch 49/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9633 - accuracy: 0.6030 - val_loss: 0.9440 - val_accuracy: 0.6280\n",
      "Epoch 50/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9629 - accuracy: 0.6011 - val_loss: 0.9435 - val_accuracy: 0.6280\n",
      "Epoch 51/200\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.9625 - accuracy: 0.6011 - val_loss: 0.9428 - val_accuracy: 0.6280\n",
      "Epoch 52/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9621 - accuracy: 0.6011 - val_loss: 0.9429 - val_accuracy: 0.6280\n",
      "Epoch 53/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9614 - accuracy: 0.6011 - val_loss: 0.9425 - val_accuracy: 0.6280\n",
      "Epoch 54/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9611 - accuracy: 0.6011 - val_loss: 0.9419 - val_accuracy: 0.6280\n",
      "Epoch 55/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9610 - accuracy: 0.6011 - val_loss: 0.9409 - val_accuracy: 0.6280\n",
      "Epoch 56/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9602 - accuracy: 0.6011 - val_loss: 0.9415 - val_accuracy: 0.6280\n",
      "Epoch 57/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9603 - accuracy: 0.6011 - val_loss: 0.9409 - val_accuracy: 0.6280\n",
      "Epoch 58/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9592 - accuracy: 0.6039 - val_loss: 0.9405 - val_accuracy: 0.6280\n",
      "Epoch 59/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9594 - accuracy: 0.6011 - val_loss: 0.9411 - val_accuracy: 0.6280\n",
      "Epoch 60/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9586 - accuracy: 0.6011 - val_loss: 0.9407 - val_accuracy: 0.6280\n",
      "Epoch 61/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9583 - accuracy: 0.6013 - val_loss: 0.9402 - val_accuracy: 0.6322\n",
      "Epoch 62/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9582 - accuracy: 0.6089 - val_loss: 0.9395 - val_accuracy: 0.6280\n",
      "Epoch 63/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9580 - accuracy: 0.6016 - val_loss: 0.9389 - val_accuracy: 0.6280\n",
      "Epoch 64/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9571 - accuracy: 0.6011 - val_loss: 0.9385 - val_accuracy: 0.6280\n",
      "Epoch 65/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9569 - accuracy: 0.6011 - val_loss: 0.9386 - val_accuracy: 0.6280\n",
      "Epoch 66/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9571 - accuracy: 0.6068 - val_loss: 0.9373 - val_accuracy: 0.6280\n",
      "Epoch 67/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9563 - accuracy: 0.6043 - val_loss: 0.9377 - val_accuracy: 0.6280\n",
      "Epoch 68/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9560 - accuracy: 0.6011 - val_loss: 0.9377 - val_accuracy: 0.6280\n",
      "Epoch 69/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9559 - accuracy: 0.6110 - val_loss: 0.9372 - val_accuracy: 0.6280\n",
      "Epoch 70/200\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.9558 - accuracy: 0.6020 - val_loss: 0.9385 - val_accuracy: 0.6440\n",
      "Epoch 71/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9550 - accuracy: 0.6018 - val_loss: 0.9364 - val_accuracy: 0.6280\n",
      "Epoch 72/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9549 - accuracy: 0.6011 - val_loss: 0.9365 - val_accuracy: 0.6280\n",
      "Epoch 73/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9548 - accuracy: 0.6011 - val_loss: 0.9359 - val_accuracy: 0.6280\n",
      "Epoch 74/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9543 - accuracy: 0.6074 - val_loss: 0.9366 - val_accuracy: 0.6280\n",
      "Epoch 75/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9550 - accuracy: 0.6011 - val_loss: 0.9360 - val_accuracy: 0.6280\n",
      "Epoch 76/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9537 - accuracy: 0.6125 - val_loss: 0.9370 - val_accuracy: 0.6280\n",
      "Epoch 77/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9543 - accuracy: 0.6011 - val_loss: 0.9359 - val_accuracy: 0.6280\n",
      "Epoch 78/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9534 - accuracy: 0.6022 - val_loss: 0.9361 - val_accuracy: 0.6499\n",
      "Epoch 79/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9534 - accuracy: 0.6137 - val_loss: 0.9357 - val_accuracy: 0.6280\n",
      "Epoch 80/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9535 - accuracy: 0.6049 - val_loss: 0.9359 - val_accuracy: 0.6280\n",
      "Epoch 81/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9533 - accuracy: 0.6026 - val_loss: 0.9351 - val_accuracy: 0.6280\n",
      "Epoch 82/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9526 - accuracy: 0.6011 - val_loss: 0.9345 - val_accuracy: 0.6280\n",
      "Epoch 83/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9522 - accuracy: 0.6011 - val_loss: 0.9348 - val_accuracy: 0.6280\n",
      "Epoch 84/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.6013 - val_loss: 0.9350 - val_accuracy: 0.6499\n",
      "Epoch 85/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9521 - accuracy: 0.6079 - val_loss: 0.9344 - val_accuracy: 0.6280\n",
      "Epoch 86/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9518 - accuracy: 0.6058 - val_loss: 0.9340 - val_accuracy: 0.6280\n",
      "Epoch 87/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9524 - accuracy: 0.6011 - val_loss: 0.9339 - val_accuracy: 0.6280\n",
      "Epoch 88/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9517 - accuracy: 0.6011 - val_loss: 0.9339 - val_accuracy: 0.6280\n",
      "Epoch 89/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9513 - accuracy: 0.6016 - val_loss: 0.9340 - val_accuracy: 0.6280\n",
      "Epoch 90/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9514 - accuracy: 0.6039 - val_loss: 0.9356 - val_accuracy: 0.6516\n",
      "Epoch 91/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9505 - accuracy: 0.6255 - val_loss: 0.9328 - val_accuracy: 0.6280\n",
      "Epoch 92/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9510 - accuracy: 0.6030 - val_loss: 0.9333 - val_accuracy: 0.6280\n",
      "Epoch 93/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9507 - accuracy: 0.6047 - val_loss: 0.9344 - val_accuracy: 0.6516\n",
      "Epoch 94/200\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.9507 - accuracy: 0.6102 - val_loss: 0.9336 - val_accuracy: 0.6322\n",
      "Epoch 95/200\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.9500 - accuracy: 0.6013 - val_loss: 0.9329 - val_accuracy: 0.6280\n",
      "Epoch 96/200\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9497 - accuracy: 0.6011 - val_loss: 0.9333 - val_accuracy: 0.6280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a1cb4ce6d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), batch_size=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá kết quả sau khi train.\\\n",
    "Nhìn chung RNN không dự đoán quá chính xác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9328 - accuracy: 0.6280\n",
      "Loss: 0.9328271150588989, Accuracy: 0.6280436515808105\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       216\n",
      "           1       0.00      0.00      0.00        81\n",
      "           2       0.00      0.00      0.00       146\n",
      "           3       0.63      1.00      0.77       748\n",
      "\n",
      "    accuracy                           0.63      1191\n",
      "   macro avg       0.16      0.25      0.19      1191\n",
      "weighted avg       0.39      0.63      0.48      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
